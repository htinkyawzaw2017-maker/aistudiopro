import warnings
warnings.filterwarnings("ignore")
import os
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GLOG_minloglevel"] = "2"

import streamlit as st
import google.generativeai as genai
import edge_tts
import subprocess
import shutil
import whisper
import time
import json
import re
import requests
import textwrap
import math

# ---------------------------------------------------------
# üé® UI SETUP (CUSTOM CSS FOR HYPER-REALISM)
# ---------------------------------------------------------
st.set_page_config(page_title="Myanmar AI Studio Pro", page_icon="üé¨", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
    <style>
    /* 1. HIDE DEFAULT STREAMLIT NAVBAR & FOOTER */
    .stApp > header {visibility: hidden;}
    .stApp > footer {visibility: hidden;}
    #MainMenu {visibility: hidden;}
    
    /* 2. GLOBAL THEME */
    .stApp { background-color: #050505; color: #e0e0e0; }
    
    /* 3. STYLING TABS AS BOXES (BUTTONS) */
    div[data-baseweb="tab-list"] {
        gap: 10px;
        background-color: transparent;
    }
    div[data-baseweb="tab"] {
        background-color: #112240;
        border-radius: 8px;
        padding: 10px 20px;
        color: #8892b0;
        border: 1px solid #233554;
        font-weight: bold;
        flex-grow: 1; /* Full width boxes */
        text-align: center;
    }
    div[data-baseweb="tab"]:hover {
        background-color: #1a2f55;
        color: white;
        border-color: #64ffda;
    }
    div[data-baseweb="tab"][aria-selected="true"] {
        background-color: #00d2ff; /* Neon Blue Active */
        color: black !important;
        border-color: #00d2ff;
        box-shadow: 0 0 10px rgba(0, 210, 255, 0.5);
    }
    
    /* 4. MAIN HEADER STYLE */
    .main-header {
        font-family: 'Helvetica Neue', sans-serif;
        background: linear-gradient(90deg, #00C9FF 0%, #92FE9D 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        padding: 10px; text-align: center; margin-bottom: 20px;
        font-size: 3rem; font-weight: 900;
        text-shadow: 0px 0px 20px rgba(0,255,136,0.3);
    }
    
    /* 5. INPUT FIELDS STYLE */
    input[type="text"], input[type="password"], textarea { 
        background-color: #0a192f !important; color: #64ffda !important; 
        border: 1px solid #112240 !important; border-radius: 8px !important;
    }
    
    /* 6. INFO BOX */
    .info-box { background: #112240; padding: 15px; border-radius: 10px; border-left: 5px solid #00d2ff; margin: 10px 0; color: white;}
    </style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# üíæ STATE MANAGEMENT
# ---------------------------------------------------------
if 'raw_transcript' not in st.session_state: st.session_state.raw_transcript = ""
if 'final_script' not in st.session_state: st.session_state.final_script = ""
if 'processed_video_path' not in st.session_state: st.session_state.processed_video_path = None
if 'processed_audio_path' not in st.session_state: st.session_state.processed_audio_path = None
if 'caption_video_path' not in st.session_state: st.session_state.caption_video_path = None
if 'api_keys' not in st.session_state: st.session_state.api_keys = []

# ---------------------------------------------------------
# üõ†Ô∏è HELPER FUNCTIONS
# ---------------------------------------------------------
# üîä SIMPLE AUDIO GENERATOR (For single chunk)

# --- LOADERS FOR DICTIONARIES ---
def load_custom_dictionary():
    # For Gemini (Text Generation)
    dict_file = "dictionary.txt"
    if os.path.exists(dict_file):
        with open(dict_file, "r", encoding="utf-8") as f: return f.read()
    return ""

def load_pronunciation_dict():
    # Pronunciation Dictionary Loader
    pron_file = "pronunciation.txt"
    replacements = {}
    if os.path.exists(pron_file):
        with open(pron_file, "r", encoding="utf-8") as f:
            for line in f:
                # "Original = Sound" ·Äï·ÄØ·Ä∂·ÄÖ·Ä∂·ÄÄ·Ä≠·ÄØ ·Äõ·Äæ·Ä¨·Äï·Äº·ÄÆ·Ä∏ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Ä¨·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
                if "=" in line and not line.startswith("#"):
                    parts = line.split("=")
                    if len(parts) == 2:
                        replacements[parts[0].strip()] = parts[1].strip()
    return replacements

def generate_single_chunk(text, lang, gender, rate_str, pitch_str, output_file):
    if not text.strip(): return False
    processed_text = normalize_text_for_tts(text) # Pronunciation & Pause logic applied here
    try:
        voice_id = VOICE_MAP.get(lang, {}).get(gender, "en-US-AriaNeural")
        cmd = ["edge-tts", "--voice", voice_id, "--text", processed_text, f"--rate={rate_str}", f"--pitch={pitch_str}", "--write-media", output_file]
        subprocess.run(cmd, stdout=subprocess.DEVNULL)
        return True
    except: return False

# Helper Functions ·Äî·Ä±·Äõ·Ä¨·Äô·Äæ·Ä¨ ·Äí·Ä´·Äú·Ä±·Ä∏ ·Äï·Äº·Äî·Ä∫·Äë·Ää·Ä∑·Ä∫·Äï·Ä±·Ä∏·Äï·Ä´
def check_requirements():
    if shutil.which("ffmpeg") is None:
        st.error("‚ùå FFmpeg is missing. Please add 'ffmpeg' to packages.txt")
        st.stop()

# ---------------------------------------------------------
# üõ†Ô∏è MISSING HELPER FUNCTIONS (Restore these)
# ---------------------------------------------------------

def get_duration(path):
    try:
        cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'json', path]
        r = subprocess.run(cmd, capture_output=True, text=True)
        return float(json.loads(r.stdout)['format']['duration'])
    except: return 0.0

def download_font():
    font_filename = "Padauk-Bold.ttf"
    if not os.path.exists(font_filename):
        url = "https://github.com/googlefonts/padauk/raw/main/fonts/ttf/Padauk-Bold.ttf"
        try:
            r = requests.get(url, timeout=10)
            with open(font_filename, 'wb') as f: f.write(r.content)
        except: pass
    return os.path.abspath(font_filename)

def load_whisper_safe():
    try: return whisper.load_model("base")
    except Exception as e: st.error(f"Whisper Error: {e}"); return None

# ---------------------------------------------------------

# üß† SMART EMOTION AUDIO ENGINE (Parses tags and merges audio)
def generate_audio_with_emotions(full_text, lang, gender, base_mode, output_file, base_speed=1.0):
    # 1. Default Settings from Base Mode
    base_settings = VOICE_MODES.get(base_mode, VOICE_MODES["Normal"])
    current_rate = int(base_settings['rate'].replace('%', ''))
    current_pitch = int(base_settings['pitch'].replace('Hz', ''))
    
    # Apply Slider Speed to Base Rate
    slider_adj = int((base_speed - 1.0) * 100)
    current_rate += slider_adj

    # 2. Split Text by Tags (e.g., [sad], [happy])
    # Regex to capture tags like [sad] and keep them as separators
    parts = re.split(r'(\[.*?\])', full_text)
    
    audio_segments = []
    chunk_idx = 0

    for part in parts:
        part = part.strip()
        if not part: continue

        # Check if this part is a Tag
        if part.lower() in EMOTION_MAP:
            # Update settings for NEXT chunks
            emo = EMOTION_MAP[part.lower()]
            # Reset to base first, then apply emotion offset
            base_r = int(base_settings['rate'].replace('%', '')) + slider_adj
            base_p = int(base_settings['pitch'].replace('Hz', ''))
            
            emo_r = int(emo['rate'].replace('%', ''))
            emo_p = int(emo['pitch'].replace('Hz', ''))
            
            current_rate = base_r + emo_r
            current_pitch = base_p + emo_p
            continue # Tag itself is not spoken
        
        # If it's Text -> Generate Audio with current settings
        chunk_filename = f"chunk_{chunk_idx}.mp3"
        rate_str = f"{current_rate:+d}%"
        pitch_str = f"{current_pitch:+d}Hz"
        
        success = generate_single_chunk(part, lang, gender, rate_str, pitch_str, chunk_filename)
        if success:
            audio_segments.append(chunk_filename)
            chunk_idx += 1

    # 3. Merge All Chunks using FFmpeg
    if not audio_segments: return False, "No audio generated"
    
    concat_list = "audio_concat.txt"
    with open(concat_list, "w") as f:
        for seg in audio_segments:
            f.write(f"file '{seg}'\n")
            
    try:
        subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_list, '-c', 'copy', output_file], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        # Cleanup temp files
        for seg in audio_segments: os.remove(seg)
        os.remove(concat_list)
        return True, "Success"
    except Exception as e:
        return False, str(e)

# ---------------------------------------------------------
# üî¢ NUMBER & TEXT NORMALIZATION
# ---------------------------------------------------------
# üî¢ NUMBER & TEXT NORMALIZATION (UPDATED)
# ---------------------------------------------------------
def num_to_burmese_spoken(num_str):
    try:
        # üî• DECIMAL FIX: 3.3 -> ·Äû·ÄØ·Ä∂·Ä∏ ·Äí·Äû·Äô ·Äû·ÄØ·Ä∂·Ä∏
        if "." in num_str:
            parts = num_str.split(".")
            if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():
                left = num_to_burmese_spoken(parts[0]) # ·Äõ·Äæ·Ä±·Ä∑·ÄÅ·Äº·Äô·Ä∫·Ä∏ (·ÅÉ)
                # ·Äî·Ä±·Ä¨·ÄÄ·Ä∫·ÄÅ·Äº·Äô·Ä∫·Ä∏ (·ÅÉ) ·ÄÄ·Ä≠·ÄØ ·Äê·ÄÖ·Ä∫·Äú·ÄØ·Ä∂·Ä∏·ÄÅ·Äª·ÄÑ·Ä∫·Ä∏·Äñ·Äê·Ä∫·Äô·Äú·Ä¨·Ä∏·Åä ·ÄÇ·Äè·Äî·Ä∫·Ä∏·Äú·Ä≠·ÄØ·Äñ·Äê·Ä∫·Äô·Äú·Ä¨·Ä∏
                # ·Äõ·Ä≠·ÄØ·Ä∏·Äõ·Ä≠·ÄØ·Ä∏·Äõ·Äæ·ÄÑ·Ä∫·Ä∏·Äõ·Äæ·ÄÑ·Ä∫·Ä∏ ·ÄÇ·Äè·Äî·Ä∫·Ä∏·Äú·Ä≠·ÄØ·Äï·Ä≤ ·Äï·Äº·Äî·Ä∫·ÄÅ·Ä±·Ä´·Ä∫·Äú·Ä≠·ÄØ·ÄÄ·Ä∫·Äô·Äö·Ä∫
                right = num_to_burmese_spoken(parts[1]) 
                return f"{left} ·Äí·Äû·Äô {right}"

        # Normal Integer Logic
        num_str = num_str.replace(",", "")
        n = int(num_str)
        if n == 0: return "·Äû·ÄØ·Ää"
        
        digit_map = ["", "·Äê·ÄÖ·Ä∫", "·Äî·Äæ·ÄÖ·Ä∫", "·Äû·ÄØ·Ä∂·Ä∏", "·Äú·Ä±·Ä∏", "·ÄÑ·Ä´·Ä∏", "·ÄÅ·Äº·Ä±·Ä¨·ÄÄ·Ä∫", "·ÄÅ·ÄØ·Äî·ÄÖ·Ä∫", "·Äõ·Äæ·ÄÖ·Ä∫", "·ÄÄ·Ä≠·ÄØ·Ä∏"]
        
        def convert_chunk(number):
            parts = []
            if number >= 10000000: parts.append(convert_chunk(number // 10000000) + "·ÄÄ·ÄØ·Äã·Ä±"); number %= 10000000
            if number >= 1000000: parts.append(digit_map[number // 1000000] + "·Äû·Äî·Ä∫·Ä∏"); number %= 1000000
            if number >= 100000: parts.append(digit_map[number // 100000] + "·Äû·Ä≠·Äî·Ä∫·Ä∏"); number %= 100000
            if number >= 10000: parts.append(digit_map[number // 10000] + "·Äû·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏"); number %= 10000
            if number >= 1000: parts.append(digit_map[number // 1000] + "·Äë·Ä±·Ä¨·ÄÑ·Ä∫"); number %= 1000
            if number >= 100: parts.append(digit_map[number // 100] + "·Äõ·Ä¨"); number %= 100
            if number >= 10: parts.append(digit_map[number // 10] + "·ÄÜ·Äö·Ä∫"); number %= 10
            if number > 0: parts.append(digit_map[number])
            return "".join(parts)

        result = convert_chunk(n)
        
        # ·Ä°·Äû·Ä∂·Äë·ÄΩ·ÄÄ·Ä∫·ÄÅ·Äª·Ä±·Ä¨·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äï·Äº·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
        result = result.replace("·Äë·Ä±·Ä¨·ÄÑ·Ä∫", "·Äë·Ä±·Ä¨·ÄÑ·Ä∑·Ä∫").replace("·Äõ·Ä¨", "·Äõ·Ä¨·Ä∑").replace("·ÄÜ·Äö·Ä∫", "·ÄÜ·Äö·Ä∑·Ä∫")
        if result.endswith("·Äë·Ä±·Ä¨·ÄÑ·Ä∑·Ä∫"): result = result[:-1] + "·ÄÑ·Ä∫"
        if result.endswith("·Äõ·Ä¨·Ä∑"): result = result[:-1]
        if result.endswith("·ÄÜ·Äö·Ä∑·Ä∫"): result = result[:-1]
        
        return result
    except: return num_str

def normalize_text_for_tts(text):
    if not text: return ""
    
    # üî• STEP 0: NUCLEAR COMMA REMOVAL (·ÄÇ·Äè·Äî·Ä∫·Ä∏·ÄÄ·Äº·Ä¨·Ä∏·ÄÄ ·ÄÄ·Ä±·Ä¨·Ä∫·Äô·Ä¨·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Ä°·Äõ·ÄÑ·Ä∫·ÄÜ·ÄØ·Ä∂·Ä∏ ·Äû·Äê·Ä∫·Äô·Äö·Ä∫)
    # 20,000 -> 20000 ·Äñ·Äº·ÄÖ·Ä∫·Äû·ÄΩ·Ä¨·Ä∏·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äú·ÄØ·Äï·Ä∫·Äû·Ä±·Ä¨ ·Ä°·ÄÜ·ÄÑ·Ä∑·Ä∫
    text = re.sub(r'(?<=\d),(?=\d)', '', text)

    # 1. Basic Symbol Cleaning
    text = text.replace("*", "").replace("#", "").replace("- ", "").replace('"', "").replace("'", "")
    
    # 2. Pronunciation Fix (Dictionary Check)
    pron_dict = load_pronunciation_dict()
    sorted_keys = sorted(pron_dict.keys(), key=len, reverse=True)
    
    for original in sorted_keys:
        fixed_sound = pron_dict[original]
        pattern = re.compile(re.escape(original), re.IGNORECASE)
        text = pattern.sub(fixed_sound, text)
        
    # 3. Pause Logic
    text = text.replace("·Åä", ", ") 
    text = text.replace("·Åã", ". ")
    text = text.replace("[p]", "... ") 
        
    # 4. Number Conversion (Regex Updated)
    # \d+ ·ÄÜ·Ä≠·ÄØ·Äê·Ä¨ ·ÄÄ·Ä±·Ä¨·Ä∫·Äô·Ä¨·Äô·Äõ·Äæ·Ä≠·Äê·Ä±·Ä¨·Ä∑·Äê·Ä≤·Ä∑ ·ÄÇ·Äè·Äî·Ä∫·Ä∏·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äõ·Äæ·Ä¨·Äê·Ä¨·Äï·Ä´
    text = re.sub(r'\b\d+(?:\.\d+)?\b', lambda x: num_to_burmese_spoken(x.group()), text)
    
    # 5. Fix "Lone Lauk Tae" (Specific Patch)
    text = text.replace("·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫ ·Äê·Ä≤·Ä∑", "·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫·Äê·Ä≤·Ä∑") 
    text = text.replace("·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫·Äû·Ä±·Ä¨", "·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫·Äê·Ä≤·Ä∑")
    
    # 6. Final Clean
    text = text.replace("\n", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text
        
    # 4. üî• REGEX UPDATE FOR DECIMALS üî•
    # ·Ä°·Äõ·ÄÑ·Ä∫·ÄÄ \b\d+\b (·ÄÇ·Äè·Äî·Ä∫·Ä∏·Äû·ÄÆ·Ä∏·Äû·Äî·Ä∑·Ä∫) ·Äï·Ä≤ ·Äõ·Äæ·Ä¨·Äê·Äö·Ä∫
    # ·Ä°·ÄÅ·ÄØ \d+(\.\d+)? (·Äí·Äû·Äô ·Äï·Ä´·Äê·Ä¨·Äõ·Ä±·Ä¨ ·Äõ·Äæ·Ä¨·Äô·Äö·Ä∫)
    text = re.sub(r'\b\d+(?:\.\d+)?\b', lambda x: num_to_burmese_spoken(x.group()), text)
    
    # 5. Fix "Lone Lauk Tae" pause issue specifically in code if Dict fails
    text = text.replace("·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫ ·Äê·Ä≤·Ä∑", "·Äú·ÄØ·Ä∂·Äú·Ä±·Ä¨·ÄÄ·Ä∫·Äê·Ä≤·Ä∑") 
    
    # 6. Final Clean
    text = text.replace("\n", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text
    
    # 1. Basic Symbol Cleaning (·Äô·Äú·Ä≠·ÄØ·Äê·Ä≤·Ä∑ ·Äû·ÄÑ·Ä∫·Äπ·ÄÄ·Ä±·Äê·Äê·ÄΩ·Ä± ·Äñ·Äö·Ä∫·Äô·Äö·Ä∫)
    text = text.replace("*", "").replace("#", "").replace("- ", "").replace('"', "").replace("'", "")
    
    # 2. PRONUNCIATION FIX (·Ä°·Äû·Ä∂·Äë·ÄΩ·ÄÄ·Ä∫ ·Äï·Äº·ÄÑ·Ä∫·ÄÜ·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏)
    pron_dict = load_pronunciation_dict()
    for original, fixed_sound in pron_dict.items():
        pattern = re.compile(re.escape(original), re.IGNORECASE)
        text = pattern.sub(fixed_sound, text)
        
    # 3. üî• PAUSE LOGIC (·Ä°·Äñ·Äº·Äê·Ä∫·Ä°·Äê·Ä±·Ä¨·ÄÄ·Ä∫ ·Äû·ÄÑ·Ä∫·Äï·Ä±·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏) üî•
    # ·Äô·Äº·Äî·Ä∫·Äô·Ä¨ '·Åä' ·ÄÄ·Ä≠·ÄØ English ',' (·ÄÄ·Ä±·Ä¨·Ä∫·Äô·Ä¨) ·Äï·Äº·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äô·Äæ AI ·ÄÄ ·ÄÅ·Äè·Äõ·Äï·Ä∫·Äê·Äê·Ä∫·Äê·Äö·Ä∫
    text = text.replace("·Åä", ", ") 
    text = text.replace("·Åã", ". ")
    
    # User ·ÄÄ [p] ·Äú·Ä≠·ÄØ·Ä∑·Äõ·Ä±·Ä∏·Äõ·ÄÑ·Ä∫ ·Ä°·ÄÄ·Äº·Ä¨·ÄÄ·Äº·ÄÆ·Ä∏·Äõ·Äï·Ä∫·Äô·Äö·Ä∑·Ä∫ logic (·Ä•·Äï·Äô·Ä¨ - ... ·Äë·Ää·Ä∑·Ä∫·Äï·Ä±·Ä∏·Äú·Ä≠·ÄØ·ÄÄ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏)
    text = text.replace("[p]", "... ") 
        
    # 4. Number Conversion
    text = re.sub(r'\b\d+\b', lambda x: num_to_burmese_spoken(x.group()), text)
    
    # 5. Remove Newlines (·Äí·Ä´·Äï·Ä±·Äô·Ä≤·Ä∑ ·Äï·ÄØ·Äí·Ä∫·Äñ·Äº·Äê·Ä∫·Äê·ÄΩ·Ä± ·ÄÄ·Äª·Äî·Ä∫·ÄÅ·Ä≤·Ä∑·Äô·Äö·Ä∫)
    text = text.replace("\n", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

# ---------------------------------------------------------
# üß† AI ENGINE
# ---------------------------------------------------------
def get_model(api_key, model_name):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(model_name)

def generate_with_retry(prompt):
    keys = st.session_state.api_keys
    # üî• AI MODEL SELECTION USAGE
    model_name = st.session_state.get("selected_model", "gemini-1.5-flash")
    custom_rules = load_custom_dictionary()
    if custom_rules:
        prompt = f"RULES:\n{custom_rules}\n\nTASK:\n{prompt}"
    for i, key in enumerate(keys):
        try:
            model = get_model(key, model_name)
            response = model.generate_content(prompt)
            return response.text
        except: continue
    return "AI Error: All keys failed."

# ---------------------------------------------------------
# üîä AUDIO ENGINE
# ---------------------------------------------------------
# üî• EMOTION SETTINGS (Tag -> Pitch/Rate Adjustments)
EMOTION_MAP = {
    "[normal]": {"rate": "+0%", "pitch": "+0Hz"},
    "[sad]":    {"rate": "-15%", "pitch": "-15Hz"},  # ·Äî·Äæ·Ä±·Ä∏·Äï·Äº·ÄÆ·Ä∏ ·Ä°·Äû·Ä∂·Äî·Ä≠·Äô·Ä∑·Ä∫·Äô·Äö·Ä∫
    "[angry]":  {"rate": "+15%", "pitch": "+5Hz"},   # ·Äô·Äº·Äî·Ä∫·Äï·Äº·ÄÆ·Ä∏ ·Ä°·Äû·Ä∂·Äô·Ä¨·Äô·Äö·Ä∫
    "[happy]":  {"rate": "+10%", "pitch": "+15Hz"},  # ·Äû·ÄΩ·ÄÄ·Ä∫·Äï·Äº·ÄÆ·Ä∏ ·Ä°·Äû·Ä∂·Äô·Äº·ÄÑ·Ä∑·Ä∫·Äô·Äö·Ä∫
    "[action]": {"rate": "+30%", "pitch": "+0Hz"},   # ·Ä°·ÄÄ·Ä∫·Äõ·Äæ·ÄÑ·Ä∫·ÄÅ·Äî·Ä∫·Ä∏ ·Äú·Ä≠·ÄØ·Äô·Äª·Ä≠·ÄØ·Ä∏ ·Ä°·Äõ·Äô·Ä∫·Ä∏·Äô·Äº·Äî·Ä∫·Äô·Äö·Ä∫
    "[whisper]": {"rate": "-10%", "pitch": "-20Hz"}, # ·Äê·Ä≠·ÄØ·Ä∏·Äê·Ä≠·ÄØ·Ä∏·Äú·Ä±·Ä∏ ·Äï·Äº·Ä±·Ä¨·Äû·Äú·Ä≠·ÄØ
}

VOICE_MAP = {
    "Burmese": {"Male": "my-MM-ThihaNeural", "Female": "my-MM-NilarNeural"},
    "English": {"Male": "en-US-ChristopherNeural", "Female": "en-US-AriaNeural"},
}
VOICE_MODES = {
    "Normal": {"rate": "+0%", "pitch": "+0Hz"},
    "Story": {"rate": "-5%", "pitch": "-2Hz"}, 
    "Recap": {"rate": "+5%", "pitch": "+0Hz"},
    "Motivation": {"rate": "+10", "pitch": "+2Hz"},
}

def generate_audio_cli(text, lang, gender, mode_name, output_file, speed_multiplier=1.0):
    if not text.strip(): return False, "Empty text"
    processed_text = normalize_text_for_tts(text)
    try:
        voice_id = VOICE_MAP.get(lang, {}).get(gender, "en-US-AriaNeural")
        settings = VOICE_MODES.get(mode_name, VOICE_MODES["Normal"])
        base_rate = int(settings['rate'].replace('%', ''))
        slider_rate = int((speed_multiplier - 1.0) * 100)
        final_rate_str = f"{base_rate + slider_rate:+d}%"
        cmd = ["edge-tts", "--voice", voice_id, "--text", processed_text, f"--rate={final_rate_str}", f"--pitch={settings['pitch']}", "--write-media", output_file]
        subprocess.run(cmd, stdout=subprocess.DEVNULL)
        return True, "Success"
    except Exception as e: return False, str(e)

# ---------------------------------------------------------
# üìù .ASS SUBTITLE
# ---------------------------------------------------------
def generate_ass_file(segments, font_path):
    filename = "captions.ass"
    def seconds_to_ass(seconds):
        h = int(seconds // 3600); m = int((seconds % 3600) // 60); s = int(seconds % 60); cs = int((seconds % 1) * 100)
        return f"{h}:{m:02d}:{s:02d}.{cs:02d}"
    header = f"""[Script Info]
ScriptType: v4.00+
PlayResX: 1920
PlayResY: 1080
WrapStyle: 0
[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: CapCut,Padauk-Bold,24,&H0000FFFF,&H000000FF,&H00000000,&H00000000,1,0,0,0,100,100,0,0,3,0,0,2,10,10,50,1
[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(header)
        for seg in segments:
            start = seconds_to_ass(seg['start'])
            end = seconds_to_ass(seg['end'])
            raw_text = seg['text'].strip()
            wrapped_lines = textwrap.wrap(raw_text, width=40)
            final_text = "\\N".join(wrapped_lines) 
            f.write(f"Dialogue: 0,{start},{end},CapCut,,0,0,0,,{final_text}\n")
    return filename

# ---------------------------------------------------------
# üñ•Ô∏è MAIN UI & SIDEBAR (UPDATED)
# ---------------------------------------------------------
st.markdown("""<div class="main-header">üé¨ Myanmar AI Studio Pro</div>""", unsafe_allow_html=True)

with st.sidebar:
    st.header("‚öôÔ∏è Control Panel")
    
    # üî• DROPDOWN MENU BAR (EXPANDER)
    with st.expander("üîë API & System Settings", expanded=True):
        # 1. API KEY (HIDDEN PASSWORD MODE)
        try:
            if "GOOGLE_API_KEYS" in st.secrets: default_keys = st.secrets["GOOGLE_API_KEYS"]
            elif "GOOGLE_API_KEY" in st.secrets: default_keys = st.secrets["GOOGLE_API_KEY"]
            else: default_keys = ""
        except: default_keys = ""
        
        api_key_input = st.text_input("API Keys (Comma separated)", value=default_keys, type="password", help="Enter multiple keys separated by comma for auto-rotation")
        
        if api_key_input:
            st.session_state.api_keys = [k.strip() for k in api_key_input.split(",") if k.strip()]
            st.success(f"‚úÖ {len(st.session_state.api_keys)} Keys Loaded")
        else: st.session_state.api_keys = []
        
        st.divider()
        
        # 2. AI MODEL SELECTOR (INCLUDED 2.0 FLASH)
        st.markdown("ü§ñ **Select AI Model:**")
        st.session_state.selected_model = st.selectbox(
            "Model Version",
            ["gemini-2.5-flash", "gemini-2.0-flash-exp"],
            index=0,
            label_visibility="collapsed"
        )
        st.caption("Tip: Use '2.0-flash-exp' for better logic.")
        
    # 3. AUTO-LOAD KNOWLEDGE BASE (No Upload Needed)
    with st.expander("üìö Knowledge & Pronunciation", expanded=False):
        st.info("üìÇ System is using internal files.")

        # Check Dictionary.txt
        if os.path.exists("dictionary.txt"):
            st.success("‚úÖ dictionary.txt: Active")
        else:
            st.error("‚ùå dictionary.txt: Missing")

        st.divider()

        # Check Pronunciation.txt
        if os.path.exists("pronunciation.txt"):
            st.success("‚úÖ pronunciation.txt: Active")
        else:
            st.error("‚ùå pronunciation.txt: Missing")
            
        if st.button("üîÑ Reload Files"):
            st.rerun()


    if st.button("üî¥ Reset System", use_container_width=True):
        for key in st.session_state.keys(): del st.session_state[key]
        st.rerun()

if not st.session_state.api_keys: st.warning("‚ö†Ô∏è Enter API Keys in Settings"); st.stop()

# üî• TABS AS BOXES (Buttons)
t1, t2, t3 = st.tabs(["üéôÔ∏è DUBBING STUDIO", "üìù AUTO CAPTION", "üöÄ VIRAL SEO"])

# === TAB 1: DUBBING STUDIO ===
with t1:
    col_up, col_set = st.columns([2, 1])
    with col_up:
        uploaded = st.file_uploader("Upload Video", type=['mp4','mov'], key="dub")
    with col_set:
        source_lang = st.selectbox("Original Lang", ["English", "Japanese", "Chinese", "Thai"])
    
    if uploaded:
        with open("input.mp4", "wb") as f: f.write(uploaded.getbuffer())
        
        if st.button("üìù Extract & Translate", use_container_width=True):
            check_requirements()
            p_bar = st.progress(0, text="Starting...")
            p_bar.progress(20, text="üé§ Transcribing Audio...")
            subprocess.run(['ffmpeg', '-y', '-i', "input.mp4", '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', 'temp.wav'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            model = load_whisper_safe()
            if model:
                raw = model.transcribe("temp.wav")['text']
                st.session_state.raw_transcript = raw
                p_bar.progress(60, text="üß† AI Translating...")
                prompt = f"Translate {source_lang} to Burmese. Input: '{raw}'. Rules: Keep Proper Nouns in English."
                st.session_state.final_script = generate_with_retry(prompt)
                p_bar.progress(100, text="‚úÖ Done!")
                st.rerun()

    

        # ‚ö†Ô∏è ·Äí·ÄÆ code block ·ÄÄ 'with t1:' ·Äõ·Ä≤·Ä∑ ·Ä°·Ä±·Ä¨·ÄÄ·Ä∫·Äô·Äæ·Ä¨ ·Äõ·Äæ·Ä≠·Äî·Ä±·Äõ·Äô·Äö·Ä∫ (Space 4 ·ÄÅ·Äª·ÄÄ·Ä∫ ·Äù·ÄÑ·Ä∫·Äî·Ä±·Äõ·Äô·Äö·Ä∫)
    if st.session_state.final_script:
        st.markdown("### üé¨ Script & Production")
        
        c_opt1, c_opt2 = st.columns(2)
        with c_opt1:
            # üî• REFINEMENT BUTTON (FORCES BURMESE OUTPUT)
            if st.button("‚ú® Refine: Storytelling Mode", use_container_width=True):
                with st.spinner("Refining Script into Burmese Storytelling Style..."):
                    prompt = f"""
                    Act as a professional Myanmar Movie Narrator.
                    Rewrite the following input text into natural, engaging **Burmese spoken language** (Storytelling Style).
                    
                    Input Text: "{st.session_state.final_script}"
                    
                    **STRICT RULES:**
                    1. **OUTPUT LANGUAGE:** MUST BE BURMESE (·Äô·Äº·Äî·Ä∫·Äô·Ä¨·ÄÖ·Ä¨) ONLY. Do not output English.
                    2. **STYLE:** Storytelling/Recap style. Use natural endings like '·Äê·Äö·Ä∫', '·Äô·Äö·Ä∫', '·Äï·Ä´'.
                    3. **FORBIDDEN:** Do NOT use '·Äó·Äª', '·Äõ·Äæ·ÄÑ·Ä∑·Ä∫', '·ÄÅ·ÄÑ·Ä∫·Äó·Äª·Ä¨', '·Äû·Ä∞·Åè', '·Åé·ÄÑ·Ä∫·Ä∏', '·Äû·Ää·Ä∫', '·Åç'.
                    4. **FLOW:** Make it continuous and exciting.
                    """
                    # AI Call
                    st.session_state.final_script = generate_with_retry(prompt)
                    st.rerun()

        with c_opt2:
             if st.button("‚Ü©Ô∏è Reset Script", use_container_width=True): pass

        txt = st.text_area("Final Script", st.session_state.final_script, height=200)
        
        # Duration Estimation
        word_count = len(txt.split())
        est_min = round(word_count / 250, 1)
        st.markdown(f"<div class='info-box'>‚è±Ô∏è Est. Duration: ~{est_min} mins</div>", unsafe_allow_html=True)
        
        c_v1, c_v2, c_v3 = st.columns(3)
        with c_v1: target_lang = st.selectbox("Output Lang", list(VOICE_MAP.keys()))
        with c_v2: gender = st.selectbox("Gender", ["Male", "Female"])
        with c_v3: v_mode = st.selectbox("Voice Mode", list(VOICE_MODES.keys()))
        
        audio_speed = st.slider("üîä Audio Speed", 0.8, 1.5, 1.0, 0.05)
        zoom_val = st.slider("üîç Copyright Zoom", 1.0, 1.2, 1.0, 0.01)
        
        with st.expander("‚ùÑÔ∏è Freeze Frame Settings"):
            c1, c2 = st.columns(2)
            auto_freeze = None; manual_freeze = None
            with c1:
                if st.checkbox("Every 30s"): auto_freeze = 30
                if st.checkbox("Every 60s"): auto_freeze = 60
            with c2: manual_freeze = st.text_input("Manual Command", placeholder="freeze 10,3")
        
        if st.button("üöÄ RENDER FINAL VIDEO", use_container_width=True):
            p_bar = st.progress(0, text="üöÄ Initializing...")
            
            p_bar.progress(30, text="üîä Generating Neural Speech (Applied Pronunciation Fix)...")
            #generate_audio_cli(txt, target_lang, gender, v_mode, "voice.mp3", speed_multiplier=audio_speed)
            # üî• CALLING NEW EMOTION ENGINE
            generate_audio_with_emotions(txt, target_lang, gender, v_mode, "voice.mp3", base_speed=audio_speed)
            st.session_state.processed_audio_path = "voice.mp3"
            
            p_bar.progress(50, text="‚ùÑÔ∏è Applying Visual Effects...")
            input_vid = "input.mp4"
            if auto_freeze or manual_freeze:
                freeze_pts = []
                dur = get_duration(input_vid)
                if auto_freeze: freeze_pts = [(t, 3) for t in range(auto_freeze, int(dur), auto_freeze)]
                elif manual_freeze:
                    match = re.search(r'freeze\s*[:=]?\s*(\d+\.?\d*)\s*,\s*(\d+\.?\d*)', manual_freeze)
                    if match: freeze_pts = [(float(match.group(1)), float(match.group(2)))]
                if freeze_pts:
                    concat_file = "concat_list.txt"
                    prev_t = 0
                    with open(concat_file, "w") as f:
                        for idx, (ft, fd) in enumerate(freeze_pts):
                            subprocess.run(['ffmpeg', '-y', '-ss', str(prev_t), '-t', str(ft-prev_t), '-i', input_vid, '-c', 'copy', f"c_{idx}.mp4"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                            f.write(f"file 'c_{idx}.mp4'\n")
                            subprocess.run(['ffmpeg', '-y', '-ss', str(ft), '-i', input_vid, '-vframes', '1', 'f.jpg'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                            subprocess.run(['ffmpeg', '-y', '-loop', '1', '-i', 'f.jpg', '-t', str(fd), '-c:v', 'libx264', '-pix_fmt', 'yuv420p', f"fr_{idx}.mp4"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                            f.write(f"file 'fr_{idx}.mp4'\n")
                            prev_t = ft
                        subprocess.run(['ffmpeg', '-y', '-ss', str(prev_t), '-i', input_vid, '-c', 'copy', "c_end.mp4"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                        f.write(f"file 'c_end.mp4'\n")
                    subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_file, '-c', 'copy', 'frozen.mp4'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    input_vid = "frozen.mp4"

            p_bar.progress(80, text="üé¨ Merging...")
            w_s = int(1920 * zoom_val); h_s = int(1080 * zoom_val)
            if w_s % 2 != 0: w_s += 1
            if h_s % 2 != 0: h_s += 1
            
            subprocess.run([
                'ffmpeg', '-y', '-i', input_vid, '-i', "voice.mp3",
                '-filter_complex', f"[0:v]scale={w_s}:{h_s},crop=1920:1080[vzoom]",
                '-map', '[vzoom]', '-map', '1:a',
                '-c:v', 'libx264', '-c:a', 'aac', '-shortest', "dubbed_final.mp4"
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            
            p_bar.progress(100, text="üéâ Complete!")
            st.session_state.processed_video_path = "dubbed_final.mp4"
            st.success("Dubbing Complete!")

    if st.session_state.processed_video_path:
        st.video(st.session_state.processed_video_path)
        c_d1, c_d2 = st.columns(2)
        with c_d1:
            with open(st.session_state.processed_video_path, "rb") as f: st.download_button("üé¨ Download Video", f, "dubbed.mp4", use_container_width=True)
        with c_d2:
            if st.session_state.processed_audio_path and os.path.exists(st.session_state.processed_audio_path):
                with open(st.session_state.processed_audio_path, "rb") as f: st.download_button("üéµ Download Audio", f, "voice.mp3", use_container_width=True)

# === TAB 2: AUTO CAPTION ===
with t2:
    st.subheader("üìù Auto Caption")
    cap_up = st.file_uploader("Upload Video", type=['mp4','mov'], key="cap")
    if cap_up:
        with open("cap_input.mp4", "wb") as f: f.write(cap_up.getbuffer())
        if st.button("Generate Captions", use_container_width=True):
            check_requirements(); font_path = download_font()
            p_bar = st.progress(0, text="Processing...")
            p_bar.progress(30, text="üé§ Transcribing...")
            subprocess.run(['ffmpeg', '-y', '-i', "cap_input.mp4", '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', 'cap.wav'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            model = load_whisper_safe()
            if model:
                segments = model.transcribe("cap.wav", task="transcribe")['segments']
                trans_segments = []
                total_seg = len(segments)
                for i, seg in enumerate(segments):
                    p_bar.progress(30 + int((i/total_seg)*50), text=f"üß† Translating {i+1}/{total_seg}")
                    txt = seg['text'].strip()
                    if txt:
                        burmese = generate_with_retry(f"Translate to Burmese. Short. Input: '{txt}'")
                        trans_segments.append({'start': seg['start'], 'end': seg['end'], 'text': burmese})
                        time.sleep(0.3)
                p_bar.progress(90, text="‚úçÔ∏è Burning Subtitles...")
                ass_file = generate_ass_file(trans_segments, font_path)
                font_dir = os.path.dirname(font_path)
                subprocess.run(['ffmpeg', '-y', '-i', "cap_input.mp4", '-vf', f"ass={ass_file}:fontsdir={font_dir}", '-c:a', 'copy', '-c:v', 'libx264', '-preset', 'fast', "captioned_final.mp4"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                st.session_state.caption_video_path = "captioned_final.mp4"
                p_bar.progress(100, text="Done!")

    if st.session_state.caption_video_path:
        st.video(st.session_state.caption_video_path)
        with open(st.session_state.caption_video_path, "rb") as f: st.download_button("Download", f, "captioned.mp4", use_container_width=True)

# === TAB 3: VIRAL SEO ===
with t3:
    st.subheader("üöÄ Viral Kit SEO")
    if st.session_state.final_script:
        if st.button("Generate Metadata", use_container_width=True):
            with st.spinner("Analyzing..."):
                prompt = f"""Based on: {st.session_state.final_script}\nGenerate:\n1. 5 Clickbait Titles (Burmese)\n2. 10 Hashtags\n3. Description"""
                seo_result = generate_with_retry(prompt)
                st.success("SEO Generated!")
                st.code(seo_result, language="markdown")
    else:
        st.info("Please generate a script in Tab 1 first.")
